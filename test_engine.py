#!/usr/bin/env python3
"""
æ¨ç†å¼•æ“æµ‹è¯•è„šæœ¬
ç›´æ¥æµ‹è¯•æ¨ç†å¼•æ“çš„åˆå§‹åŒ–å’ŒåŠ è½½è¿‡ç¨‹
"""

import os
import sys

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

def test_inference_engine():
    """æµ‹è¯•æ¨ç†å¼•æ“"""
    print("ğŸ” æµ‹è¯•æ¨ç†å¼•æ“åˆå§‹åŒ–...")
    
    try:
        from inference.factory import InferenceFactory
        from utils.platform_detector import auto_detect_platform
        
        # è‡ªåŠ¨æ£€æµ‹å¹³å°
        platform = auto_detect_platform()
        print(f"âœ… æ£€æµ‹åˆ°å¹³å°: {platform}")
        
        # æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
        model_path = None
        for root, dirs, files in os.walk("models"):
            for filename in files:
                if filename.endswith('.onnx'):
                    model_path = os.path.join(root, filename)
                    print(f"âœ… æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_path}")
                    break
            if model_path:
                break
        
        if not model_path:
            print("âŒ æœªæ‰¾åˆ°ONNXæ¨¡å‹æ–‡ä»¶")
            return False
        
        # åˆ›å»ºæ¨ç†å¼•æ“
        config = {
            'confidence_threshold': 0.5,
            'nms_threshold': 0.4,
            'input_size': [640, 640],
            'labels': ['person']
        }
        
        print(f"ğŸ”„ åˆ›å»ºæ¨ç†å¼•æ“: {platform}")
        engine = InferenceFactory.create_engine(
            platform=platform,
            model_path=model_path,
            config=config
        )
        
        if not engine:
            print("âŒ æ¨ç†å¼•æ“åˆ›å»ºå¤±è´¥")
            return False
        
        print("âœ… æ¨ç†å¼•æ“åˆ›å»ºæˆåŠŸ")
        
        # åŠ è½½æ¨¡å‹
        print("ğŸ”„ åŠ è½½æ¨¡å‹...")
        if engine.load_model():
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            
            # æµ‹è¯•ç®€å•æ¨ç†
            print("ğŸ”„ æµ‹è¯•æ¨ç†...")
            import cv2
            import numpy as np
            
            # åˆ›å»ºæµ‹è¯•å›¾åƒ
            test_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
            
            try:
                detections, inference_time = engine.detect(test_image)
                print(f"âœ… æ¨ç†æµ‹è¯•æˆåŠŸ! æ£€æµ‹åˆ° {len(detections)} ä¸ªç›®æ ‡ï¼Œè€—æ—¶ {inference_time:.4f}s")
                
                # æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡
                stats = engine.get_performance_stats()
                print(f"ğŸ“Š æ€§èƒ½ç»Ÿè®¡: {stats}")
                
                return True
            except Exception as e:
                print(f"âŒ æ¨ç†æµ‹è¯•å¤±è´¥: {e}")
                return False
        else:
            print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ æ¨ç†å¼•æ“æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("ğŸš€ AI Edgeæ¨ç†å¼•æ“æµ‹è¯•")
    print("=" * 50)
    
    if test_inference_engine():
        print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
    else:
        print("âŒ æµ‹è¯•å¤±è´¥!")
        sys.exit(1) 