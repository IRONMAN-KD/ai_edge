"""
AI Edgeç»Ÿä¸€APIæœåŠ¡
æ”¯æŒå¤šå¹³å°æ¨ç†å¼•æ“ï¼Œé›†æˆæ•°æ®åº“ç®¡ç†
"""

import os
import sys
import argparse
import logging
import asyncio
import numpy as np
import cv2
from typing import Optional, Dict, Any, List
from contextlib import asynccontextmanager
import time
import concurrent.futures

from fastapi import FastAPI, HTTPException, UploadFile, File, Form, Depends, APIRouter, status, WebSocket, WebSocketDisconnect, Query, Body
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from fastapi.security import OAuth2PasswordBearer, OAuth2PasswordRequestForm
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
import uvicorn

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from inference.factory import InferenceFactory
from utils.platform_detector import auto_detect_platform
from utils.config_parser import ConfigParser

# æ•°æ®åº“ç›¸å…³å¯¼å…¥
from database.database import DatabaseManager
from database.repositories import ModelRepository, UserRepository, TaskRepository, AlertRepository, SystemConfigRepository
from database.models import (
    Model, ModelCreate, ModelUpdate, ModelStatusUpdate, User, UserCreate, Task, TaskCreate, Alert, AlertCreate,
    PaginatedModelResponse, PaginatedTaskResponse, PaginatedAlertResponse
)

# ç»„ä»¶å¯¼å…¥
from components.task_scheduler import TaskScheduler

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å…¨å±€å˜é‡
inference_engine = None
app_config = None
db_manager = None
model_repository = None
user_repository = None
task_repository = None
alert_repository = None
config_repository = None
current_model = None
task_scheduler = None

# OAuth2é…ç½®
oauth2_scheme = OAuth2PasswordBearer(tokenUrl="token")

# åˆ›å»ºAPIè·¯ç”±å™¨
api_router = APIRouter(prefix="/api/v1")

@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    # å¯åŠ¨æ—¶åˆå§‹åŒ–
    logger.info("ğŸš€ AI Edge APIæœåŠ¡å¯åŠ¨ä¸­...")
    await initialize_services()
    
    yield
    
    # å…³é—­æ—¶æ¸…ç†
    logger.info("ğŸ›‘ AI Edge APIæœåŠ¡å…³é—­ä¸­...")
    await cleanup_services()

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="AI Edgeç»Ÿä¸€API",
    description="æ”¯æŒå¤šå¹³å°çš„AIæ¨ç†æœåŠ¡",
    version="2.0.0",
    lifespan=lifespan
)

# CORSé…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# é™æ€æ–‡ä»¶æœåŠ¡
ALERT_IMAGE_DIR = "alert_images"
if not os.path.exists(ALERT_IMAGE_DIR):
    os.makedirs(ALERT_IMAGE_DIR)
app.mount("/alert_images", StaticFiles(directory=ALERT_IMAGE_DIR), name="alert_images")

async def initialize_services():
    """åˆå§‹åŒ–æœåŠ¡"""
    global inference_engine, app_config, db_manager, model_repository, user_repository
    global task_repository, alert_repository, config_repository, current_model, task_scheduler
    
    try:
        # 1. åˆå§‹åŒ–æ•°æ®åº“è¿æ¥ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
        logger.info("ğŸ”— åˆå§‹åŒ–æ•°æ®åº“è¿æ¥...")
        
        # æ•°æ®åº“è¿æ¥é‡è¯•æœºåˆ¶
        max_retries = 30
        retry_interval = 2
        db_connected = False
        
        # åˆå§‹åŒ–å˜é‡
        db_manager = None
        model_repository = None
        user_repository = None
        task_repository = None
        alert_repository = None
        config_repository = None
        
        for attempt in range(1, max_retries + 1):
            try:
                db_manager = DatabaseManager()
                model_repository = ModelRepository()
                user_repository = UserRepository()
                task_repository = TaskRepository()
                alert_repository = AlertRepository()
                config_repository = SystemConfigRepository()
                
                # æµ‹è¯•æ•°æ®åº“è¿æ¥
                test_query = "SELECT 1"
                db_manager.execute_query(test_query, fetch='one')
                logger.info("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
                db_connected = True
                break
                
            except Exception as e:
                logger.warning(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥ (å°è¯• {attempt}/{max_retries}): {e}")
                if attempt < max_retries:
                    logger.info(f"ç­‰å¾… {retry_interval} ç§’åé‡è¯•...")
                    await asyncio.sleep(retry_interval)
                else:
                    logger.error("âŒ æ•°æ®åº“è¿æ¥æœ€ç»ˆå¤±è´¥ï¼ŒæœåŠ¡å°†åœ¨æ— æ•°æ®åº“æ¨¡å¼ä¸‹å¯åŠ¨")
        
        # 2. è·å–å¹³å°å‚æ•°
        platform = os.getenv('PLATFORM')
        if not platform:
            platform = auto_detect_platform()
            logger.info(f"è‡ªåŠ¨æ£€æµ‹åˆ°å¹³å°: {platform}")
        else:
            logger.info(f"ä½¿ç”¨æŒ‡å®šå¹³å°: {platform}")
        
        # 3. åŠ è½½é…ç½®
        config_path = f"configs/platforms/{platform}/platform.yml"
        if os.path.exists(config_path):
            app_config = ConfigParser(config_path)
            logger.info(f"åŠ è½½å¹³å°é…ç½®: {config_path}")
        else:
            logger.warning(f"å¹³å°é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            app_config = ConfigParser()
        
        # 4. ä»æ•°æ®åº“è·å–æ¿€æ´»çš„æ¨¡å‹
        model_path = None
        if model_repository:
            active_models = model_repository.get_all_models(page=1, page_size=1, status='active')
        else:
            active_models = {'items': []}
        if active_models['items']:
            current_model = active_models['items'][0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ¿€æ´»çš„æ¨¡å‹
            model_path = current_model.file_path
            logger.info(f"ä»æ•°æ®åº“åŠ è½½æ¨¡å‹: {current_model.name} ({model_path})")
        else:
            # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰æ¨¡å‹ï¼Œå°è¯•ä»æ–‡ä»¶ç³»ç»Ÿè·å–
            model_path = get_model_path(platform)
            if model_path:
                logger.info(f"ä»æ–‡ä»¶ç³»ç»Ÿæ‰¾åˆ°æ¨¡å‹: {model_path}")
                # å°†æ¨¡å‹æ·»åŠ åˆ°æ•°æ®åº“
                if model_repository:
                    try:
                        model_create = ModelCreate(
                            name="person_detection",
                            version="1.0",
                            type="object_detection",
                            file_path=model_path,
                            description="è‡ªåŠ¨å¯¼å…¥çš„äººå‘˜æ£€æµ‹æ¨¡å‹"
                        )
                        current_model = model_repository.create_model(model_create)
                        logger.info(f"æ¨¡å‹å·²æ·»åŠ åˆ°æ•°æ®åº“: {current_model.id}")
                    except Exception as e:
                        logger.warning(f"æ·»åŠ æ¨¡å‹åˆ°æ•°æ®åº“å¤±è´¥: {e}")
                else:
                    logger.warning("æ•°æ®åº“ä¸å¯ç”¨ï¼Œæ— æ³•æ·»åŠ æ¨¡å‹åˆ°æ•°æ®åº“")
            else:
                logger.warning(f"æœªæ‰¾åˆ°{platform}å¹³å°çš„æ¨¡å‹æ–‡ä»¶ï¼ŒAPIæœåŠ¡å°†åœ¨æ— æ¨¡å‹æ¨¡å¼ä¸‹å¯åŠ¨")
        
        # 5. åˆ›å»ºæ¨ç†å¼•æ“
        if model_path and os.path.exists(model_path):
            inference_config = app_config.get_section('inference') or {}
            inference_engine = InferenceFactory.create_engine(
                platform=platform,
                model_path=model_path,
                config=inference_config
            )
            
            # åŠ è½½æ¨¡å‹
            if inference_engine.load_model(model_path):
                logger.info("âœ… æ¨ç†å¼•æ“åˆå§‹åŒ–æˆåŠŸ")
            else:
                logger.error("âŒ æ¨ç†å¼•æ“åˆå§‹åŒ–å¤±è´¥")
                inference_engine = None
        else:
            logger.warning(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨æˆ–æœªæŒ‡å®š: {model_path}ï¼Œæ¨ç†åŠŸèƒ½å°†ä¸å¯ç”¨")
            inference_engine = None
        
        # 6. åˆ›å»ºä»»åŠ¡è°ƒåº¦å™¨
        task_scheduler = TaskScheduler(app_config)
        task_scheduler.start()
        
    except Exception as e:
        logger.error(f"æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
        inference_engine = None

async def cleanup_services():
    """æ¸…ç†æœåŠ¡"""
    global inference_engine, task_scheduler
    
    if task_scheduler:
        try:
            task_scheduler.stop()
            logger.info("ä»»åŠ¡è°ƒåº¦å™¨å·²åœæ­¢")
        except Exception as e:
            logger.error(f"ä»»åŠ¡è°ƒåº¦å™¨åœæ­¢å¤±è´¥: {e}")
    
    if inference_engine:
        try:
            inference_engine.release_resources()
            logger.info("æ¨ç†å¼•æ“èµ„æºå·²é‡Šæ”¾")
        except Exception as e:
            logger.error(f"èµ„æºé‡Šæ”¾å¤±è´¥: {e}")

def get_model_path(platform: str) -> Optional[str]:
    """è·å–æ¨¡å‹æ–‡ä»¶è·¯å¾„"""
    model_dir = "models"
    
    if not os.path.exists(model_dir):
        return None
    
    # å¹³å°ç‰¹å®šçš„æ¨¡å‹æ–‡ä»¶æ‰©å±•å
    model_extensions = {
        'nvidia_gpu': ['.onnx', '.trt', '.engine'],
        'atlas_npu': ['.om'],
        'sophon': ['.bmodel'],
        'cpu_x86': ['.onnx'],
        'cpu_arm': ['.onnx']
    }
    
    extensions = model_extensions.get(platform, ['.onnx'])
    
    # é€’å½’æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
    for root, dirs, files in os.walk(model_dir):
        for filename in files:
            for ext in extensions:
                if filename.endswith(ext):
                    model_path = os.path.join(root, filename)
                    logger.info(f"æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_path}")
                    return model_path
    
    return None

# ==================== åŸºç¡€ç«¯ç‚¹ ====================

@app.get("/")
async def root():
    """æ ¹ç«¯ç‚¹"""
    return {
        "message": "AI Edgeç»Ÿä¸€APIæœåŠ¡",
        "version": "2.0.0",
        "status": "running"
    }

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    # æµ‹è¯•æ•°æ®åº“è¿æ¥
    db_status = "disconnected"
    if db_manager and model_repository:
        try:
            db_manager.execute_query("SELECT 1", fetch='one')
            db_status = "connected"
        except Exception as e:
            db_status = f"error: {str(e)}"
    
    return {
        "status": "healthy",
        "database": db_status,
        "inference_engine": "ready" if inference_engine else "not_ready",
        "current_model": current_model.name if current_model else None
    }

@app.get("/platform/info")
async def get_platform_info():
    """è·å–å¹³å°ä¿¡æ¯"""
    platform = os.getenv('PLATFORM', auto_detect_platform())
    supported_platforms = InferenceFactory.get_supported_platforms()
    
    return {
        "current_platform": platform,
        "supported_platforms": supported_platforms,
        "inference_engine_status": "ready" if inference_engine else "not_ready",
        "model_loaded": current_model.name if current_model else None
    }

# ==================== ç”¨æˆ·è®¤è¯ ====================

@api_router.post("/auth/login")
async def login(form_data: OAuth2PasswordRequestForm = Depends()):
    """ç”¨æˆ·ç™»å½•"""
    user = user_repository.authenticate_user(form_data.username, form_data.password)
    if not user:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯",
            headers={"WWW-Authenticate": "Bearer"},
        )
    # è¿™é‡Œåº”è¯¥ç”ŸæˆJWT tokenï¼Œç®€åŒ–ç‰ˆæœ¬ç›´æ¥è¿”å›ç”¨æˆ·ä¿¡æ¯
    return {"access_token": f"token_{user.id}", "token_type": "bearer", "user": user}

@api_router.post("/users/", response_model=User)
async def create_user(user: UserCreate):
    """åˆ›å»ºç”¨æˆ·"""
    return user_repository.create_user(user)

@api_router.get("/users/me/", response_model=User)
async def read_users_me():
    """è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯"""
    # ç®€åŒ–ç‰ˆæœ¬ï¼Œå®é™…åº”è¯¥ä»tokenä¸­è§£æç”¨æˆ·
    return {"id": 1, "username": "admin", "email": "admin@example.com"}

# ==================== æ¨¡å‹ç®¡ç† ====================

@api_router.post("/models/", response_model=Model)
async def create_model(model: ModelCreate):
    """åˆ›å»ºæ¨¡å‹"""
    return model_repository.create_model(model)

@api_router.get("/models", response_model=PaginatedModelResponse)
async def get_models(
    page: int = Query(1, ge=1),
    page_size: int = Query(10, ge=1, le=100),
    keyword: Optional[str] = None,
    status: Optional[str] = None,
    type: Optional[str] = None
):
    """è·å–æ¨¡å‹åˆ—è¡¨"""
    if not model_repository:
        raise HTTPException(status_code=503, detail="æ•°æ®åº“æœåŠ¡ä¸å¯ç”¨")
    
    result = model_repository.get_all_models(
        page=page, page_size=page_size, keyword=keyword, status=status, type=type
    )
    return PaginatedModelResponse(**result)

@api_router.get("/models/{model_id}", response_model=Model)
async def get_model(model_id: int):
    """è·å–å•ä¸ªæ¨¡å‹"""
    model = model_repository.get_model_by_id(model_id)
    if not model:
        raise HTTPException(status_code=404, detail="æ¨¡å‹ä¸å­˜åœ¨")
    return model

@api_router.put("/models/{model_id}", response_model=Model)
async def update_model(model_id: int, model_update: ModelUpdate):
    """æ›´æ–°æ¨¡å‹ä¿¡æ¯"""
    updated_model = model_repository.update_model(model_id, model_update)
    if not updated_model:
        raise HTTPException(status_code=404, detail="æ¨¡å‹ä¸å­˜åœ¨")
    return updated_model

@api_router.put("/models/{model_id}/status", response_model=Model)
async def update_model_status(model_id: int, status_data: dict):
    """æ›´æ–°æ¨¡å‹çŠ¶æ€ï¼ˆå¯ç”¨/ç¦ç”¨ï¼‰"""
    status = status_data.get("status")
    if status not in ["active", "inactive"]:
        raise HTTPException(status_code=400, detail="æ— æ•ˆçš„çŠ¶æ€å€¼")
    
    model_repository.update_model_status(model_id, status)
    updated_model = model_repository.get_model_by_id(model_id)
    if not updated_model:
        raise HTTPException(status_code=404, detail="æ¨¡å‹ä¸å­˜åœ¨")
    return updated_model

@api_router.post("/models/upload", response_model=Model)
async def upload_model(
    name: str = Form(...),
    version: str = Form("1.0"),
    model_type: str = Form(..., alias="type"),
    description: Optional[str] = Form(None),
    file: UploadFile = File(...)
):
    """ä¸Šä¼ æ¨¡å‹æ–‡ä»¶"""
    import os
    import json
    
    # åˆ›å»ºæ¨¡å‹ç›®å½•
    models_dir = "models"
    os.makedirs(models_dir, exist_ok=True)
    
    # å®‰å…¨çš„æ–‡ä»¶åå¤„ç†
    sanitized_filename = os.path.basename(file.filename)
    if not sanitized_filename:
        raise HTTPException(status_code=400, detail="æ— æ•ˆçš„æ–‡ä»¶å")
        
    file_location = os.path.join(models_dir, sanitized_filename)

    # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
    try:
        with open(file_location, "wb+") as file_object:
            contents = await file.read()
            file_object.write(contents)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ–‡ä»¶ä¿å­˜å¤±è´¥: {e}")

    # åˆ›å»ºæ•°æ®åº“è®°å½•
    model_data = ModelCreate(
        name=name,
        version=version,
        type=model_type,
        description=description,
        file_path=sanitized_filename
    )

    try:
        db_model = model_repository.create_model(model_data)
        return db_model
    except Exception as e:
        # å¦‚æœæ•°æ®åº“æ“ä½œå¤±è´¥ï¼Œåˆ é™¤å·²ä¸Šä¼ çš„æ–‡ä»¶
        try:
            os.remove(file_location)
        except:
            pass
        raise HTTPException(status_code=500, detail=f"æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")

@api_router.delete("/models/{model_id}", status_code=status.HTTP_204_NO_CONTENT)
async def delete_model(model_id: int):
    """åˆ é™¤æ¨¡å‹ï¼ˆåªèƒ½åˆ é™¤ç¦ç”¨çŠ¶æ€çš„æ¨¡å‹ï¼‰"""
    model = model_repository.get_model_by_id(model_id)
    if not model:
        raise HTTPException(status_code=404, detail="æ¨¡å‹ä¸å­˜åœ¨")
    
    # æ£€æŸ¥æ¨¡å‹çŠ¶æ€ï¼Œåªæœ‰ç¦ç”¨çŠ¶æ€çš„æ¨¡å‹æ‰èƒ½åˆ é™¤
    if model.status == 'active':
        raise HTTPException(status_code=400, detail="æ— æ³•åˆ é™¤å¯ç”¨çŠ¶æ€çš„æ¨¡å‹ï¼Œè¯·å…ˆç¦ç”¨æ¨¡å‹")
    
    success = model_repository.delete_model_by_id(model_id)
    if not success:
        raise HTTPException(status_code=500, detail="åˆ é™¤æ¨¡å‹å¤±è´¥")
    
    return None  # 204çŠ¶æ€ç ä¸éœ€è¦è¿”å›å†…å®¹ï¼Œä½†éœ€è¦æ˜¾å¼è¿”å›

# æ¨¡å‹éƒ¨ç½²
@api_router.post("/models/{model_id}/deploy")
async def deploy_model(model_id: int):
    """éƒ¨ç½²æ¨¡å‹"""
    model = model_repository.get_model_by_id(model_id)
    if not model:
        raise HTTPException(status_code=404, detail="æ¨¡å‹ä¸å­˜åœ¨")
    
    # ç®€åŒ–å®ç°ï¼Œæ›´æ–°çŠ¶æ€ä¸ºactive
    updated_model = model_repository.update_model_status(model_id, "active")
    return {"message": "æ¨¡å‹éƒ¨ç½²æˆåŠŸ", "model": updated_model}

# å–æ¶ˆéƒ¨ç½²æ¨¡å‹
@api_router.post("/models/{model_id}/undeploy")
async def undeploy_model(model_id: int):
    """å–æ¶ˆéƒ¨ç½²æ¨¡å‹"""
    model = model_repository.get_model_by_id(model_id)
    if not model:
        raise HTTPException(status_code=404, detail="æ¨¡å‹ä¸å­˜åœ¨")
    
    # ç®€åŒ–å®ç°ï¼Œæ›´æ–°çŠ¶æ€ä¸ºinactive
    updated_model = model_repository.update_model_status(model_id, "inactive")
    return {"message": "æ¨¡å‹å–æ¶ˆéƒ¨ç½²æˆåŠŸ", "model": updated_model}

# è·å–æ¨¡å‹ç‰ˆæœ¬åˆ—è¡¨
@api_router.get("/models/{model_id}/versions")
async def get_model_versions(model_id: int):
    """è·å–æ¨¡å‹ç‰ˆæœ¬åˆ—è¡¨"""
    model = model_repository.get_model_by_id(model_id)
    if not model:
        raise HTTPException(status_code=404, detail="æ¨¡å‹ä¸å­˜åœ¨")
    
    # ç®€åŒ–å®ç°ï¼Œè¿”å›å½“å‰ç‰ˆæœ¬
    versions = [{"version": model.version, "created_at": model.upload_time, "status": model.status}]
    return {"versions": versions}

# è·å–æ¨¡å‹æ€§èƒ½æŒ‡æ ‡
@api_router.get("/models/{model_id}/metrics")
async def get_model_metrics(model_id: int):
    """è·å–æ¨¡å‹æ€§èƒ½æŒ‡æ ‡"""
    model = model_repository.get_model_by_id(model_id)
    if not model:
        raise HTTPException(status_code=404, detail="æ¨¡å‹ä¸å­˜åœ¨")
    
    # ç®€åŒ–å®ç°ï¼Œè¿”å›æ¨¡æ‹ŸæŒ‡æ ‡
    metrics = {
        "accuracy": 0.95,
        "inference_time": 0.05,
        "memory_usage": 512,
        "throughput": 100
    }
    return {"metrics": metrics}

# æ‰¹é‡æ“ä½œæ¨¡å‹
class BatchModelUpdateRequest(BaseModel):
    ids: List[int]
    action: str  # activate, deactivate, delete
    
@api_router.put("/models/batch")
async def batch_update_models(update_request: BatchModelUpdateRequest):
    """æ‰¹é‡æ“ä½œæ¨¡å‹"""
    for model_id in update_request.ids:
        if update_request.action == "activate":
            model_repository.update_model_status(model_id, "active")
        elif update_request.action == "deactivate":
            model_repository.update_model_status(model_id, "inactive")
        elif update_request.action == "delete":
            model_repository.delete_model(model_id)
    return {"message": f"æ‰¹é‡æ“ä½œå®Œæˆ: {update_request.action}"}

# å¯¼å‡ºæ¨¡å‹é…ç½®
@api_router.get("/models/{model_id}/export")
async def export_model(model_id: int):
    """å¯¼å‡ºæ¨¡å‹é…ç½®"""
    model = model_repository.get_model_by_id(model_id)
    if not model:
        raise HTTPException(status_code=404, detail="æ¨¡å‹ä¸å­˜åœ¨")
    
    # ç®€åŒ–å®ç°ï¼Œè¿”å›æ¨¡å‹é…ç½®
    config = {
        "name": model.name,
        "version": model.version,
        "type": model.type,
        "description": model.description
    }
    return {"config": config}

# å¯¼å…¥æ¨¡å‹é…ç½®
@api_router.post("/models/import")
async def import_model(file: UploadFile = File(...)):
    """å¯¼å…¥æ¨¡å‹é…ç½®"""
    # ç®€åŒ–å®ç°
    content = await file.read()
    return {"message": "æ¨¡å‹é…ç½®å¯¼å…¥æˆåŠŸ", "imported_count": 0}

# ==================== ä»»åŠ¡ç®¡ç† ====================

@api_router.post("/tasks", response_model=Task)
async def create_task(task: TaskCreate):
    """åˆ›å»ºæ–°ä»»åŠ¡"""
    return task_repository.create_task(task)

@api_router.get("/tasks", response_model=PaginatedTaskResponse)
async def get_tasks(
    page: int = Query(1, ge=1),
    page_size: int = Query(10, ge=1, le=100),
    keyword: Optional[str] = None,
    status: Optional[str] = None,
    model_id: Optional[int] = None,
    is_enabled: Optional[bool] = None
):
    """è·å–ä»»åŠ¡åˆ—è¡¨ï¼ˆæ”¯æŒç­›é€‰ï¼‰"""
    return task_repository.get_all_tasks(
        page=page, page_size=page_size, keyword=keyword,
        status=status, model_id=model_id, is_enabled=is_enabled
    )

# ä»»åŠ¡ç»Ÿè®¡ - æ”¾åœ¨{task_id}è·¯ç”±ä¹‹å‰
@api_router.get("/tasks/stats")
async def get_task_stats():
    """è·å–ä»»åŠ¡ç»Ÿè®¡ä¿¡æ¯"""
    counts = task_repository.get_task_counts_by_status()
    total = task_repository.get_total_count()
    return {
        "total": total,
        "counts_by_status": counts,
        "active_tasks": counts.get("running", 0) + counts.get("pending", 0)
    }

# è·å–è¿è¡Œä¸­çš„ä»»åŠ¡ - æ”¾åœ¨{task_id}è·¯ç”±ä¹‹å‰
@api_router.get("/tasks/running")
async def get_running_tasks():
    """è·å–è¿è¡Œä¸­çš„ä»»åŠ¡"""
    running_tasks = task_repository.get_tasks_by_status("running")
    return {"tasks": running_tasks, "count": len(running_tasks)}

# å¯¼å‡ºä»»åŠ¡ - æ”¾åœ¨{task_id}è·¯ç”±ä¹‹å‰
@api_router.get("/tasks/export")
async def export_tasks():
    """å¯¼å‡ºä»»åŠ¡æ•°æ®"""
    tasks = task_repository.get_all_tasks()['items']
    return {"data": tasks, "total": len(tasks)}

# å¯¼å…¥ä»»åŠ¡ - æ”¾åœ¨{task_id}è·¯ç”±ä¹‹å‰
@api_router.post("/tasks/import")
async def import_tasks(file: UploadFile = File(...)):
    """å¯¼å…¥ä»»åŠ¡æ•°æ®"""
    # ç®€åŒ–å®ç°
    content = await file.read()
    return {"message": "ä»»åŠ¡å¯¼å…¥æˆåŠŸ", "imported_count": 0}

# è·å–è§†é¢‘å¸§ç”¨äºROIé€‰æ‹© - æ”¾åœ¨{task_id}è·¯ç”±ä¹‹å‰
class FrameRequest(BaseModel):
    source: str

@api_router.post("/tasks/frame")
async def get_task_frame(request: FrameRequest):
    """è·å–è§†é¢‘å¸§ç”¨äºROIé€‰æ‹©"""
    import base64
    def read_frame_from_source(source, timeout=5):
        import cv2, time
        cap = cv2.VideoCapture(source)
        if not cap.isOpened():
            cap.release()
            return None
        start_time = time.time()
        frame = None
        while time.time() - start_time < timeout:
            ret, frame = cap.read()
            if ret:
                break
            time.sleep(0.1)
        cap.release()
        return frame if ret else None
    loop = asyncio.get_event_loop()
    with concurrent.futures.ThreadPoolExecutor() as pool:
        frame = await loop.run_in_executor(pool, read_frame_from_source, request.source, 5)
    if frame is None:
        raise HTTPException(status_code=404, detail="æ— æ³•ä»è§†é¢‘æºè¯»å–å¸§ï¼ˆè¶…æ—¶ï¼‰")
    is_success, buffer = cv2.imencode(".jpg", frame)
    if not is_success:
        raise HTTPException(status_code=500, detail="å¸§ç¼–ç å¤±è´¥")
    jpg_as_text = base64.b64encode(buffer).decode('utf-8')
    return {"frame": "data:image/jpeg;base64," + jpg_as_text}

# æ‰¹é‡æ“ä½œä»»åŠ¡ - æ”¾åœ¨{task_id}è·¯ç”±ä¹‹å‰
class BatchTaskUpdateRequest(BaseModel):
    ids: List[int]
    action: str  # start, stop, delete
    
@api_router.put("/tasks/batch")
async def batch_update_tasks(update_request: BatchTaskUpdateRequest):
    """æ‰¹é‡æ“ä½œä»»åŠ¡"""
    for task_id in update_request.ids:
        if update_request.action == "start":
            # å¯åŠ¨ä»»åŠ¡é€»è¾‘
            pass
        elif update_request.action == "stop":
            # åœæ­¢ä»»åŠ¡é€»è¾‘
            pass
        elif update_request.action == "delete":
            task_repository.delete_task(task_id)
    return {"message": f"æ‰¹é‡æ“ä½œå®Œæˆ: {update_request.action}"}

@api_router.get("/tasks/{task_id}", response_model=Task)
async def get_task(task_id: int):
    """è·å–å•ä¸ªä»»åŠ¡è¯¦æƒ…"""
    task = task_repository.get_task_by_id(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    return task

@api_router.put("/tasks/{task_id}", response_model=Task)
async def update_task(task_id: int, task: TaskCreate):
    """æ›´æ–°ä»»åŠ¡"""
    updated_task = task_repository.update_task(task_id, task)
    if not updated_task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    return updated_task

@api_router.post("/tasks/{task_id}/start", status_code=status.HTTP_204_NO_CONTENT)
async def start_task(task_id: int):
    """å¯åŠ¨ä»»åŠ¡"""
    task = task_repository.get_task_by_id(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    # æ›´æ–°æ•°æ®åº“ä¸­çš„ä»»åŠ¡çŠ¶æ€å’Œå¯ç”¨çŠ¶æ€
    task_repository.update_task_status_and_enabled_state(task_id, "running", True)
    
    # è°ƒç”¨ä»»åŠ¡è°ƒåº¦å™¨å¯åŠ¨ä»»åŠ¡
    if task_scheduler:
        task_scheduler.start_task_manually(task_id)
    
    logger.info(f"ä»»åŠ¡ {task_id} å·²å¯åŠ¨")

@api_router.post("/tasks/{task_id}/stop", status_code=status.HTTP_204_NO_CONTENT)
async def stop_task(task_id: int):
    """åœæ­¢ä»»åŠ¡"""
    task = task_repository.get_task_by_id(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    # æ›´æ–°æ•°æ®åº“ä¸­çš„ä»»åŠ¡çŠ¶æ€å’Œå¯ç”¨çŠ¶æ€
    task_repository.update_task_status_and_enabled_state(task_id, "stopped", False)
    
    # è°ƒç”¨ä»»åŠ¡è°ƒåº¦å™¨åœæ­¢ä»»åŠ¡
    if task_scheduler:
        task_scheduler.stop_task_manually(task_id)
    
    logger.info(f"ä»»åŠ¡ {task_id} å·²åœæ­¢")

@api_router.delete("/tasks/{task_id}", status_code=status.HTTP_204_NO_CONTENT)
async def delete_task(task_id: int):
    """åˆ é™¤ä»»åŠ¡"""
    success = task_repository.delete_task(task_id)
    if not success:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

@api_router.get("/tasks/{task_id}/status")
async def get_task_runtime_status(task_id: int):
    """è·å–ä»»åŠ¡è¿è¡Œæ—¶çŠ¶æ€"""
    task = task_repository.get_task_by_id(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    # æ£€æŸ¥ä»»åŠ¡è°ƒåº¦å™¨ä¸­çš„çŠ¶æ€
    runtime_status = "unknown"
    if task_scheduler:
        runtime_status = task_scheduler.get_task_status(task_id)
    
    return {
        "task_id": task_id,
        "database_status": task.status,
        "runtime_status": runtime_status,
        "is_enabled": task.is_enabled
    }

# ä»»åŠ¡æ—¥å¿—
@api_router.get("/tasks/{task_id}/logs")
async def get_task_logs(task_id: int, limit: int = Query(100, ge=1, le=1000)):
    """è·å–ä»»åŠ¡æ—¥å¿—"""
    task = task_repository.get_task_by_id(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    # ç®€åŒ–å®ç°ï¼Œè¿”å›æ¨¡æ‹Ÿæ—¥å¿—
    logs = [
        {"timestamp": "2024-01-01T12:00:00Z", "level": "INFO", "message": f"Task {task_id} started"},
        {"timestamp": "2024-01-01T12:01:00Z", "level": "INFO", "message": f"Processing video stream for task {task_id}"},
    ]
    return {"logs": logs[:limit]}

# ==================== å‘Šè­¦ç®¡ç† ====================

@api_router.get("/alerts", response_model=PaginatedAlertResponse)
async def get_alerts(
    page: int = Query(1, ge=1),
    page_size: int = Query(10, ge=1, le=100),
    keyword: Optional[str] = None,
    level: Optional[str] = None,
    status: Optional[str] = None,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None
):
    """è·å–å‘Šè­¦åˆ—è¡¨"""
    return alert_repository.get_all_alerts(
        page=page, page_size=page_size, keyword=keyword, level=level,
        status=status, start_date=start_date, end_date=end_date
    )

# å‘Šè­¦ç»Ÿè®¡ - æ”¾åœ¨{alert_id}è·¯ç”±ä¹‹å‰
@api_router.get("/alerts/stats")
async def get_alert_stats():
    """è·å–å‘Šè­¦ç»Ÿè®¡"""
    counts_by_status = alert_repository.get_alert_counts_by_status()
    counts_by_day = alert_repository.get_alert_counts_by_day(days=7)
    latest_alerts = alert_repository.get_latest_alerts(limit=5)
    
    return {
        "counts_by_status": counts_by_status,
        "counts_by_day": counts_by_day,
        "latest_alerts": latest_alerts
    }

# å‘Šè­¦è¶‹åŠ¿ - æ”¾åœ¨{alert_id}è·¯ç”±ä¹‹å‰
@api_router.get("/alerts/trends")
async def get_alert_trends():
    """è·å–å‘Šè­¦è¶‹åŠ¿"""
    trends = alert_repository.get_alert_counts_by_day(days=30)
    return {"trends": trends}

# å¯¼å‡ºå‘Šè­¦ - æ”¾åœ¨{alert_id}è·¯ç”±ä¹‹å‰
@api_router.get("/alerts/export")
async def export_alerts():
    """å¯¼å‡ºå‘Šè­¦æ•°æ®"""
    # ç®€åŒ–å®ç°ï¼Œè¿”å›JSONæ ¼å¼
    alerts = alert_repository.get_all_alerts()['items']
    return {"data": alerts, "total": len(alerts)}

# å‘Šè­¦é…ç½® - æ”¾åœ¨{alert_id}è·¯ç”±ä¹‹å‰
@api_router.get("/alerts/config")
async def get_alert_config():
    """è·å–å‘Šè­¦é…ç½®"""
    return config_repository.get_config("alert_settings", {})

@api_router.put("/alerts/config")
async def update_alert_config(config: Dict[str, Any]):
    """æ›´æ–°å‘Šè­¦é…ç½®"""
    config_repository.update_config("alert_settings", config)
    return {"message": "å‘Šè­¦é…ç½®æ›´æ–°æˆåŠŸ"}

# æ‰¹é‡æ“ä½œå‘Šè­¦ - æ”¾åœ¨{alert_id}è·¯ç”±ä¹‹å‰
class BatchAlertUpdateRequest(BaseModel):
    ids: List[int]
    status: str
    remark: Optional[str] = None

@api_router.put("/alerts/batch", status_code=status.HTTP_204_NO_CONTENT)
async def batch_update_alerts(update_request: BatchAlertUpdateRequest):
    """æ‰¹é‡æ›´æ–°å‘Šè­¦çŠ¶æ€"""
    for alert_id in update_request.ids:
        alert_repository.update_alert_status(
            alert_id, update_request.status, update_request.remark
        )

@api_router.get("/alerts/{alert_id}")
async def get_alert(alert_id: int):
    """è·å–å•ä¸ªå‘Šè­¦è¯¦æƒ…"""
    alert = alert_repository.get_alert_by_id(alert_id)
    if not alert:
        raise HTTPException(status_code=404, detail="å‘Šè­¦ä¸å­˜åœ¨")
    return alert

@api_router.put("/alerts/{alert_id}", response_model=Alert)
async def update_alert(alert_id: int, data: dict = Body(...)):
    """
    æ›´æ–°å•æ¡å‘Šè­¦ï¼ˆå…¼å®¹å‰ç«¯ï¼‰
    """
    alert = alert_repository.update_alert_status(
        alert_id, data.get("status"), data.get("remark")
    )
    if not alert:
        raise HTTPException(status_code=404, detail="å‘Šè­¦ä¸å­˜åœ¨")
    return alert

@api_router.delete("/alerts/{alert_id}", status_code=status.HTTP_204_NO_CONTENT)
async def delete_alert(alert_id: int):
    """
    åˆ é™¤å•æ¡å‘Šè­¦ï¼ˆå…¼å®¹å‰ç«¯ï¼‰
    """
    success = alert_repository.delete_alert(alert_id)
    if not success:
        raise HTTPException(status_code=404, detail="å‘Šè­¦ä¸å­˜åœ¨")

# ==================== æ¨ç†æ¥å£ ====================

@api_router.post("/inference/detect")
async def detect_objects(
    file: UploadFile = File(...),
    confidence_threshold: float = Form(0.5),
    nms_threshold: float = Form(0.4)
):
    """ç›®æ ‡æ£€æµ‹æ¥å£"""
    if not inference_engine:
        raise HTTPException(status_code=503, detail="æ¨ç†å¼•æ“æœªå°±ç»ª")
    
    try:
        # è¯»å–å›¾ç‰‡
        contents = await file.read()
        nparr = np.frombuffer(contents, np.uint8)
        image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        
        if image is None:
            raise HTTPException(status_code=400, detail="æ— æ•ˆçš„å›¾ç‰‡æ–‡ä»¶")
        
        # æ‰§è¡Œæ¨ç†
        results = inference_engine.detect(
            image, 
            confidence_threshold=confidence_threshold,
            nms_threshold=nms_threshold
        )
        
        return {
            "status": "success",
            "results": results,
            "inference_time": inference_engine.get_performance_stats().get("last_inference_time", 0)
        }
        
    except Exception as e:
        logger.error(f"æ¨ç†å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ¨ç†å¤±è´¥: {str(e)}")

# ==================== ç³»ç»Ÿé…ç½® ====================

@api_router.get("/config")
async def get_system_config():
    """è·å–ç³»ç»Ÿé…ç½®"""
    return config_repository.get_all_configs()

@api_router.put("/config")
async def update_system_config(configs: Dict[str, Any]):
    """æ›´æ–°ç³»ç»Ÿé…ç½®"""
    config_repository.update_configs(configs)
    return {"message": "é…ç½®æ›´æ–°æˆåŠŸ"}

# ==================== ç³»ç»Ÿç»Ÿè®¡ ====================

@api_router.get("/system/stats")
async def get_system_stats():
    """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯ - å·²ä¿®å¤ç‰ˆæœ¬"""
    # è·å–ä»»åŠ¡ç»Ÿè®¡
    task_counts = task_repository.get_task_counts_by_status()
    total_tasks = task_repository.get_total_count()
    
    # è·å–æ¨¡å‹ç»Ÿè®¡
    model_total = model_repository.get_total_count()
    active_models = len(model_repository.get_all_models(status='active')['items'])
    
    # è·å–å‘Šè­¦ç»Ÿè®¡
    alert_counts = alert_repository.get_alert_counts_by_status()
    recent_alerts = len(alert_repository.get_latest_alerts(limit=10))
    
    # æ‰å¹³ç»“æ„ï¼ˆå‘åå…¼å®¹ï¼‰
    stats = {
        "total_tasks": total_tasks,
        "pending": task_counts.get("pending", 0),
        "running": task_counts.get("running", 0),
        "completed": task_counts.get("completed", 0),
        "failed": task_counts.get("failed", 0),
        "total_models": model_total,
        "active_models": active_models,
        "total_alerts": recent_alerts,
        "unresolved_alerts": alert_counts.get("unresolved", 0),
        "resolved_alerts": alert_counts.get("resolved", 0),
        "models": {
            "total": model_total,
            "active": active_models
        },
        "tasks": {
            "total": total_tasks,
            "counts_by_status": task_counts
        },
        "alerts": {
            "counts_by_status": alert_counts,
            "recent": recent_alerts
        },
        
        # å‰ç«¯DashboardæœŸæœ›çš„åµŒå¥—ç»“æ„
        "summary": {
            "total_tasks": total_tasks,
            "running_tasks": task_counts.get("running", 0),
            "total_models": model_total,
            "pending_alerts": alert_counts.get("unresolved", 0)
        },
        "alerts_by_status": {
            "pending": alert_counts.get("unresolved", 0),
            "processing": alert_counts.get("processing", 0),
            "resolved": alert_counts.get("resolved", 0)
        },
        "alerts_past_week": [],  # æš‚æ—¶ä¸ºç©ºï¼Œå¯ä»¥åç»­å®ç°
        "latest_alerts": []  # æš‚æ—¶ä¸ºç©ºï¼Œå¯ä»¥åç»­å®ç°
    }
    
    if inference_engine:
        stats["inference"] = inference_engine.get_performance_stats()
    
    # å¼ºåˆ¶æ·»åŠ æµ‹è¯•å­—æ®µ
    stats["test_summary"] = {
        "total_tasks": total_tasks,
        "running_tasks": task_counts.get("running", 0),
        "total_models": model_total,
        "pending_alerts": alert_counts.get("unresolved", 0)
    }
    
    return stats

@api_router.get("/system/configs")
async def get_system_configs():
    """è·å–ç³»ç»Ÿé…ç½® (å…¼å®¹æ€§ç«¯ç‚¹)"""
    return config_repository.get_all_configs()

@api_router.put("/system/configs")
async def update_system_configs(configs: Dict[str, Any]):
    """æ›´æ–°ç³»ç»Ÿé…ç½® (å…¼å®¹æ€§ç«¯ç‚¹)"""
    config_repository.update_configs(configs)
    return {"message": "System configurations updated successfully."}

# ==================== è§†é¢‘æµæ”¯æŒ ====================

async def generate_mjpeg_stream(video_source_url: str):
    """
    Generates an MJPEG stream from a video source.
    """
    import cv2
    import concurrent.futures
    import asyncio
    cap = None
    loop = asyncio.get_event_loop()
    try:
        logger.info(f"Opening MJPEG stream for: {video_source_url}")
        source_to_open = int(video_source_url) if video_source_url.isdigit() else video_source_url
        cap = cv2.VideoCapture(source_to_open)
        if not cap.isOpened():
            logger.error(f"Cannot open video source: {video_source_url}")
            return
        def read_frame():
            ret, frame = cap.read()
            return ret, frame
        with concurrent.futures.ThreadPoolExecutor() as pool:
            while True:
                ret, frame = await loop.run_in_executor(pool, read_frame)
                if not ret:
                    logger.warning(f"Lost connection to video stream: {video_source_url}. Stopping stream.")
                    break
                _, buffer = cv2.imencode('.jpg', frame)
                frame_data = buffer.tobytes()
                yield (b'--frame\r\n'
                       b'Content-Type: image/jpeg\r\n\r\n' + frame_data + b'\r\n')
    except Exception as e:
        logger.error(f"An unexpected error occurred in MJPEG stream for {video_source_url}: {e}")
    finally:
        if cap:
            cap.release()
        logger.info(f"Client disconnected from stream: {video_source_url}. Closing resources.")

@api_router.get("/tasks/{task_id}/stream")
async def mjpeg_video_stream(task_id: int):
    """MJPEGè§†é¢‘æµç«¯ç‚¹"""
    task = task_repository.get_task_by_id(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    if not task.video_sources:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡æ²¡æœ‰è§†é¢‘æº")

    # For simplicity, we stream the first video source of the task
    first_source = task.video_sources[0]
    if isinstance(first_source, dict):
        video_source_url = first_source.get('url', first_source.get('source', ''))
    elif isinstance(first_source, str):
        video_source_url = first_source
    else:
        video_source_url = ''
    if not video_source_url:
        raise HTTPException(status_code=400, detail="æ— æ•ˆçš„è§†é¢‘æºæ ¼å¼")
    from fastapi.responses import StreamingResponse
    return StreamingResponse(
        generate_mjpeg_stream(video_source_url),
        media_type='multipart/x-mixed-replace; boundary=frame'
    )

# ==================== WebSocketæ”¯æŒ ====================

@app.websocket("/ws/tasks/{task_id}/stream")
async def websocket_task_stream(websocket: WebSocket, task_id: int):
    """ä»»åŠ¡å®æ—¶æµWebSocket"""
    await websocket.accept()
    try:
        while True:
            # è¿™é‡Œåº”è¯¥å®ç°å®æ—¶è§†é¢‘æµå¤„ç†
            # ç®€åŒ–ç‰ˆæœ¬åªå‘é€å¿ƒè·³
            await websocket.send_json({"type": "heartbeat", "task_id": task_id})
            await asyncio.sleep(1)
    except WebSocketDisconnect:
        logger.info(f"WebSocketè¿æ¥æ–­å¼€: task_id={task_id}")

# æ³¨å†ŒAPIè·¯ç”±
app.include_router(api_router)

# ==================== å¯åŠ¨é…ç½® ====================

def parse_args():
    parser = argparse.ArgumentParser(description="AI Edgeç»Ÿä¸€APIæœåŠ¡")
    parser.add_argument("--host", default="0.0.0.0", help="æœåŠ¡å™¨åœ°å€")
    parser.add_argument("--port", type=int, default=8000, help="æœåŠ¡å™¨ç«¯å£")
    parser.add_argument("--reload", action="store_true", help="å¼€å‘æ¨¡å¼çƒ­é‡è½½")
    return parser.parse_args()

def main():
    args = parse_args()
    
    logger.info(f"å¯åŠ¨AI Edge APIæœåŠ¡ - {args.host}:{args.port}")
    uvicorn.run(
        "main:app",
        host=args.host,
        port=args.port,
        reload=args.reload
    )

if __name__ == "__main__":
    main()
